import pandas as pd
import numpy as np
from scipy.sparse import load_npz
from sklearn.ensemble import RandomForestClassifier
from sklearn.model_selection import train_test_split
from sklearn.metrics import classification_report, confusion_matrix
from sklearn.impute import SimpleImputer
from imblearn.over_sampling import SMOTE
import joblib

print("ğŸ“¥ Chargement des donnÃ©es encodÃ©es...")
X = load_npz("output/preprocessed_data.npz")
y = pd.read_csv("output/target.csv").values.ravel()

print(f"ğŸ“Š Dimensions X : {X.shape}")
print(f"ğŸ¯ Dimensions y : {y.shape}")
print("ğŸ” Distribution des classes dans y :", dict(zip(*np.unique(y, return_counts=True))))

print("ğŸ§¹ VÃ©rification de la prÃ©sence de NaN dans la sparse matrix...")
if np.isnan(X.data).any():
    print("âš ï¸ Des NaN dÃ©tectÃ©s dans la sparse matrix, application d'une imputation...")
    imputer = SimpleImputer(strategy="constant", fill_value=0)
    X = imputer.fit_transform(X)
else:
    print("âœ… Aucune valeur manquante dÃ©tectÃ©e dans la sparse matrix.")

print("ğŸ§ª Split avec stratification sur y...")
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, stratify=y, random_state=42
)
print(f"ğŸ“Š Train : {X_train.shape}, Test : {X_test.shape}")
print("ğŸ“Š Classes dans le train :", dict(zip(*np.unique(y_train, return_counts=True))))
print("ğŸ“Š Classes dans le test :", dict(zip(*np.unique(y_test, return_counts=True))))

# RÃ©Ã©quilibrage
if len(np.unique(y_train)) > 1:
    print("ğŸ”„ RÃ©Ã©quilibrage avec SMOTE...")
    smote = SMOTE(random_state=42)
    X_train_resampled, y_train_resampled = smote.fit_resample(X_train, y_train)
    print(f"âœ… AprÃ¨s SMOTE : {X_train_resampled.shape}, {y_train_resampled.shape}")
    print("ğŸ“Š Classes aprÃ¨s SMOTE :", dict(zip(*np.unique(y_train_resampled, return_counts=True))))
else:
    print("âš ï¸ SMOTE ignorÃ© : une seule classe dÃ©tectÃ©e dans y_train.")
    X_train_resampled, y_train_resampled = X_train, y_train

print("ğŸ§  EntraÃ®nement du RandomForestClassifier...")
model = RandomForestClassifier(n_jobs=-1, random_state=42)
model.fit(X_train_resampled, y_train_resampled)

print("ğŸ§¾ Ã‰valuation sur le jeu de test...")
y_pred = model.predict(X_test)
print(confusion_matrix(y_test, y_pred))
print(classification_report(y_test, y_pred, digits=4))

accuracy = np.mean(y_pred == y_test)
print(f"âœ… Accuracy : {accuracy:.4f}")

print("ğŸ’¾ Sauvegarde du modÃ¨le dans output/random_forest_model.joblib")
joblib.dump(model, "output/random_forest_model.joblib")
